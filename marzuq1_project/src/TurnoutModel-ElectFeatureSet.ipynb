{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 117 ms, total: 1.39 s\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import *\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import NullPool\n",
    "from textwrap import dedent\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_election_filename = 'id_l2_2016_10_05_voters'\n",
    "post_election_filename ='id_l2_2017_03_20_voters'\n",
    "scores = 'id_l2_2016_10_05_scores'\n",
    "flags = 'id_l2_2016_10_05_flags'\n",
    "featureset_filename = 'id_l2_2016_10_05_featureset_1354'\n",
    "featureset_scoring_filename = 'id_l2_2016_10_05_featureset_1354_scoring'\n",
    "featureset_cols_filename = 'id_l2_2016_10_05_featureset_1354_names'\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "# pre_election_filename = 'ne_cd_2_l2_2016_10_03_voters'\n",
    "# post_election_filename ='ne_cd_2_l2_2017_01_13_voters'\n",
    "# scores = 'ne_cd_2_l2_2016_10_03_scores'\n",
    "# flags = 'ne_cd_2_l2_2016_10_03_flags'\n",
    "# featureset_filename = 'ne_cd_2_l2_2016_10_03_featureset_1335'\n",
    "# featureset_scoring_filename = 'ne_cd_2_l2_2016_10_03_featureset_1335_scoring'\n",
    "# featureset_cols_filename = 'ne_cd_2_l2_2016_10_03_featureset_1335_names'\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "# pre_election_filename = 'ca_cd_49_l2_2016_09_29_voters'\n",
    "# post_election_filename ='ca_cd_49_l2_2017_03_25_voters'\n",
    "# scores = 'ca_cd_49_l2_2016_09_29_scores'\n",
    "# flags = 'ca_cd_49_l2_2016_09_29_flags'\n",
    "# featureset_filename = 'ca_cd_49_l2_2016_09_29_featureset_1336'\n",
    "# featureset_scoring_filename = 'ca_cd_49_l2_2016_09_29_featureset_1336_scoring'\n",
    "# featureset_cols_filename = 'ca_cd_49_l2_2016_09_29_featureset_1336_names'\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# pre_election_filename = 'ny_cd_22_l2_2016_10_23_voters'\n",
    "# post_election_filename ='ny_cd_22_l2_2017_03_14_voters'\n",
    "# scores = 'ny_cd_22_l2_2016_10_23_scores'\n",
    "# flags = 'ny_cd_22_l2_2016_10_23_flags'\n",
    "# featureset_filename = 'ny_cd_22_l2_2016_10_23_featureset_1295'\n",
    "# featureset_scoring_filename = 'ny_cd_22_l2_2016_10_23_featureset_1295_scoring'\n",
    "# featureset_cols_filename = 'ny_cd_22_l2_2016_10_23_featureset_1295_names'\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# pre_election_filename = 'fl_cd_18_l2_2016_10_08_voters'\n",
    "# post_election_filename ='fl_cd_18_l2_2017_01_27_voters'\n",
    "# scores = 'fl_cd_18_l2_2016_10_08_scores'\n",
    "# flags = 'fl_cd_18_l2_2016_10_08_flags'\n",
    "# featureset_filename = 'fl_cd_18_l2_2016_10_08_featureset_1294'\n",
    "# featureset_scoring_filename = 'fl_cd_18_l2_2016_10_08_featureset_1294_scoring'\n",
    "# featureset_cols_filename = 'fl_cd_18_l2_2016_10_08_featureset_1294_names'\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# pre_election_filename = 'co_cd_6_l2_2016_10_13_voters'\n",
    "# post_election_filename ='co_cd_6_l2_2016_12_15_voters'\n",
    "# scores = 'co_cd_6_l2_2016_10_13_scores'\n",
    "# flags = 'co_cd_6_l2_2016_10_13_flags'\n",
    "# featureset_filename = 'co_cd_6_l2_2016_10_13_featureset_1302'\n",
    "# featureset_scoring_filename = 'co_cd_6_l2_2016_10_13_featureset_1302_scoring'\n",
    "# featureset_cols_filename = 'co_cd_6_l2_2016_10_13_featureset_1302_names'\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# pre_election_filename = 'tx_cd_23_l2_2016_09_30_voters'\n",
    "# post_election_filename ='tx_cd_23_l2_2017_03_12_voters'\n",
    "# scores = 'tx_cd_23_l2_2016_09_30_scores'\n",
    "# flags = 'tx_cd_23_l2_2016_09_30_flags'\n",
    "# featureset_filename = 'tx_cd_23_l2_2016_09_30_featureset_1296'\n",
    "# featureset_scoring_filename = 'tx_cd_23_l2_2016_09_30_featureset_1296_scoring'\n",
    "# featureset_cols_filename = 'tx_cd_23_l2_2016_09_30_featureset_1296_names'\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "proxy_election_date = {'year':2012,\n",
    "                     'month':11,\n",
    "                     'day':6\n",
    "                    }\n",
    "target_election_date = {'year':2016,\n",
    "                     'month':11,\n",
    "                     'day':8\n",
    "                    }\n",
    "today = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'connection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0da231f0229d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'connection' is not defined"
     ]
    }
   ],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# establish connection\n",
    "DB_CONNECTION = os.environ['DB_CONNECTION'] if 'DB_CONNECTION' in os.environ else 'postgresql://datauser:zeroptimus@10.0.199.20:5432/turnout_modelling_project'\n",
    "connection_url = DB_CONNECTION\n",
    "cm_engine = create_engine(connection_url, poolclass=NullPool)\n",
    "connection = cm_engine.connect()\n",
    "\n",
    "# load pre_election_voterfile\n",
    "query1 = dedent(f\"\"\"\n",
    "    select  *\n",
    "        from \"{pre_election_filename}\";\n",
    "        \"\"\")\n",
    "print('---- loading pre election voter file ------')\n",
    "pre_election = pd.read_sql_query(query1, connection)\n",
    "\n",
    "\n",
    "## load post_election_voterfile\n",
    "query2 = dedent(f\"\"\"\n",
    "    select  *\n",
    "        from \"{post_election_filename}\";\n",
    "        \"\"\")\n",
    "print('---- loading post election voter file -------')\n",
    "post_election = pd.read_sql_query(query2, connection)\n",
    "\n",
    "## load flags table\n",
    "query3 = dedent(f\"\"\"\n",
    "    select * from \"{flags}\";\n",
    "    \"\"\")\n",
    "print('---- loading flags table ------')\n",
    "flags = pd.read_sql_query(query3, connection)\n",
    "\n",
    "\n",
    "## load scores table\n",
    "query4 = dedent(f\"\"\"\n",
    "    select * \n",
    "    from \"{scores}\";\n",
    "    \"\"\")\n",
    "print('---- loading scores table -----')\n",
    "scores = pd.read_sql_query(query4, connection)\n",
    "\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "# Imputes missing values\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if ( (X[c].dtype == np.dtype('O')) | (X[c].dtype.name =='category')) else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# establish connection\n",
    "DB_CONNECTION = os.environ['DB_CONNECTION'] if 'DB_CONNECTION' in os.environ else 'postgresql://datauser:zeroptimus@10.0.199.20:5432/elect_data'\n",
    "connection_url = DB_CONNECTION\n",
    "cm_engine = create_engine(connection_url, poolclass=NullPool)\n",
    "connection = cm_engine.connect()\n",
    "\n",
    "# load featureset train\n",
    "query5 = dedent(f\"\"\"\n",
    "    select  *\n",
    "        from \"{featureset_filename}\";\n",
    "        \"\"\")\n",
    "print('---- loading train featureset ------')\n",
    "featureset_train = pd.read_sql_query(query5, connection)\n",
    "\n",
    "# load featureset score\n",
    "query6 = dedent(f\"\"\"\n",
    "    select  *\n",
    "        from \"{featureset_scoring_filename}\";\n",
    "        \"\"\")\n",
    "print('---- loading score featureset ------')\n",
    "featureset_score = pd.read_sql_query(query6, connection)\n",
    "\n",
    "## load post_election_voterfile\n",
    "query7 = dedent(f\"\"\"\n",
    "    select  *\n",
    "        from \"{featureset_cols_filename}\";\n",
    "        \"\"\")\n",
    "print('---- loading feature names -------')\n",
    "featureset_cols = pd.read_sql_query(query7, connection)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_election.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elect_featureset_train = pd.DataFrame(featureset_train['features'].values.tolist(), columns=featureset_cols.name.tolist())\n",
    "elect_featureset_train['lalvoterid'] = featureset_train['lalvoterid']\n",
    "\n",
    "elect_featureset_score = pd.DataFrame(featureset_score['features'].values.tolist(), columns=featureset_cols.name.tolist())\n",
    "elect_featureset_score['lalvoterid'] = featureset_score['lalvoterid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elect_featureset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elect_featureset_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #save featureset as csv\n",
    "# elect_featureset_train.to_csv(''.join([featureset_filename,'.csv']))\n",
    "# elect_featureset_score.to_csv(''.join([featureset_scoring_filename,'.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elect_drop = ['age','age_squared', 'age_cubed', 'age_null', 'age_18_34', 'age_35_54',\n",
    "       'age_55_plus', 'birth_date_offset', 'calculated_reg_date_offset',\n",
    "       'official_reg_date_offset']\n",
    "\n",
    "elect_add = ['lalvoterid','norm_population_by_reg_zip', 'reg_zip_not_republican',\n",
    "       'reg_zip_not_white', 'norm_population_by_precinct',\n",
    "       'precinct_not_republican', 'precinct_not_white', 'birth_years',\n",
    "       'birth_years_squared', 'birth_years_cubed', 'birth_years_group',\n",
    "       'calculated_reg_years', 'calculated_reg_years_group',\n",
    "       'precinct_percent_turnout_4g', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pre_election = add_features(pre_election)\n",
    "\n",
    "train = add_features_date(pre_election, proxy_election_date)\n",
    "#train_ft = first_time_voters(train, flags, 'first_time_voter_12g')\n",
    "train_ft = train\n",
    "\n",
    "# copy responses col as y\n",
    "train_ft['y'] = train_ft['vh_2012g']\n",
    "\n",
    "# combine the featureset with new variables\n",
    "train_mixed = elect_featureset_train.drop(elect_drop, axis=1).merge(train_ft[elect_add], how='inner',on='lalvoterid')\n",
    "\n",
    "# Data Imputation \n",
    "train_ft_imputed =  DataFrameImputer().fit_transform(train_mixed)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "num_cols = train_ft_imputed._get_numeric_data().columns\n",
    "cols = train_ft_imputed.columns\n",
    "cat_cols = list(set(cols)- set(num_cols))\n",
    "cat_cols.remove('lalvoterid')\n",
    "print(cat_cols)\n",
    "\n",
    "# dummy out train data\n",
    "train_ft_imputed_dummied = pd.get_dummies(train_ft_imputed, columns=cat_cols)\n",
    "print('Shape of featureset = ', train_ft_imputed_dummied.shape)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import log_loss\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "# Don't need this for tree based algorithms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = train_ft_imputed_dummied.drop('lalvoterid',axis = 1)\n",
    "X = X.drop('y', axis = 1)\n",
    "y = train_ft_imputed_dummied['y']\n",
    "#scaler = StandardScaler(copy=False, with_mean=True, with_std=True)\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "clf = xgb.XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=3,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=0.5,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "\n",
    "log_loss_scores = cross_val_score(clf, X, y, cv=5, scoring='neg_log_loss', n_jobs= -1)\n",
    "print('Mean log loss score =', log_loss_scores.mean(), 'Variance of log loss score =', log_loss_scores.var())\n",
    "\n",
    "# retrain on the entire training data\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = add_features_date(pre_election, target_election_date)\n",
    "\n",
    "#test_ft = first_time_voters(test, flags, 'first_time_voter')\n",
    "test_ft = test\n",
    "# get the 2016g column from post election voter file\n",
    "test_ft = test_ft.merge(post_election[['lalvoterid','vh_2016g']], how='inner',on='lalvoterid')\n",
    "\n",
    "# duplicate the column vh_2012g by y\n",
    "test_ft['y'] = test_ft['vh_2016g']\n",
    "\n",
    "#drop few columns from elect featureset and add substitutes\n",
    "test_mixed = elect_featureset_score.drop(elect_drop, axis=1).merge(test_ft[elect_add], how='inner',on='lalvoterid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# data imputation\n",
    "test_ft_imputed =  DataFrameImputer().fit_transform(test_mixed)\n",
    "# dummy out data\n",
    "test_ft_imputed_dummied = pd.get_dummies(test_ft_imputed, columns=cat_cols)\n",
    "#train_ft_imputed_dummied = pd.read_csv('trainft_imputed_dummied.csv')\n",
    "\n",
    "XX_target_election = test_ft_imputed_dummied.drop('lalvoterid',axis = 1)\n",
    "XX_target_election = XX_target_election.drop('y',axis=1)\n",
    "\n",
    "cols_diff = list(set(X.columns.values.tolist()).symmetric_difference(XX_target_election.columns.values.tolist()))\n",
    "for k in range(0, len(cols_diff)):\n",
    "     XX_target_election[cols_diff[k]] = 0\n",
    "        \n",
    "use_cols = X.columns.values.tolist()\n",
    "results = test_ft_imputed_dummied[['lalvoterid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['turnout_ft_score'] = [e1[1] for e1 in clf.predict_proba(XX_target_election[use_cols])]\n",
    "#results['turnout_ft_prediction'] = clf.predict(XX_target_election[use_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame(columns=['FeatureNames','FeatureImportance'])\n",
    "feature_importance['FeatureNames'] = X.columns.values.tolist()\n",
    "feature_importance['FeatureImportance'] = clf.feature_importances_.tolist()\n",
    "feature_importance = feature_importance.sort_values(by='FeatureImportance', ascending=False)\n",
    "feature_importance[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_predictions = test_ft_imputed_dummied.merge(scores[['lalvoterid','turnout_2016g']], how='left', on='lalvoterid')[['lalvoterid','turnout_2016g']]\n",
    "trad_predictions = trad_predictions.merge(flags, how='left', on='lalvoterid')\n",
    "all_predictions = results.merge(trad_predictions, how='left', on='lalvoterid')\n",
    "all_predictions = all_predictions.merge(test_ft_imputed_dummied[['lalvoterid','y']],how='left', on='lalvoterid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_predictions = pd.read_csv('predictions_turnout_vh2016g_tx_cd_23_l2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mixed['birth_years_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mixed['birth_years_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score,f1_score\n",
    "print('----------- Results from traditional method -------------------')\n",
    "print('Accuracy = ', accuracy_score(all_predictions['y'],all_predictions['likely_voter_or_p']))\n",
    "print('Recall = ', recall_score(all_predictions['y'],all_predictions['likely_voter_or_p']))\n",
    "print('F1 score = ', f1_score(all_predictions['y'],all_predictions['likely_voter_or_p']))\n",
    "\n",
    "sns.heatmap(confusion_matrix(all_predictions['y'],all_predictions['likely_voter_or_p']).astype('float')/all_predictions.shape[0], \n",
    "            cmap=\"Blues\", annot=True, annot_kws={'size': 14},\n",
    "            vmin=0, vmax=1);\n",
    "plt.xlabel('Predicted label', fontsize = 16);\n",
    "plt.ylabel('Actual label', fontsize = 16);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerged = pd.merge(pre_election, post_election, how='inner',on='lalvoterid')\n",
    "dfmerged = pd.merge(dfmerged, flags, how='inner',on='lalvoterid')\n",
    "dfmerged = pd.merge(dfmerged, scores, how='inner',on='lalvoterid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerged['0ptimus_score_prediction'] = [1 if x >=0.5 else 0 for x in dfmerged['turnout_2016g']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('----------- Results from Elect2 model -------------------')\n",
    "print('Accuracy = ', accuracy_score(dfmerged['vh_2016g'],dfmerged['0ptimus_score_prediction']))\n",
    "print('Recall = ', recall_score(dfmerged['vh_2016g'],dfmerged['0ptimus_score_prediction']))\n",
    "\n",
    "sns.heatmap(confusion_matrix(dfmerged['vh_2016g'],dfmerged['0ptimus_score_prediction']).astype('float')/dfmerged.shape[0],\n",
    "            cmap=\"Blues\", annot=True, annot_kws={'size': 14},\n",
    "            vmin=0, vmax=1);\n",
    "plt.xlabel('Predicted label', fontsize = 16);\n",
    "plt.ylabel('Actual label', fontsize = 16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('----------- Results from New model -------------------')\n",
    "print('Accuracy = ', accuracy_score(all_predictions['y'],all_predictions['turnout_ft_prediction']))\n",
    "print('Recall = ', recall_score(all_predictions['y'], all_predictions['turnout_ft_prediction']))\n",
    "\n",
    "sns.heatmap(confusion_matrix(all_predictions['y'],all_predictions['turnout_ft_prediction']).astype('float')/all_predictions.shape[0],\n",
    "            cmap=\"Blues\", annot=True, annot_kws={'size': 14},\n",
    "            vmin=0, vmax=1);\n",
    "plt.xlabel('Predicted label', fontsize = 16);\n",
    "plt.ylabel('Actual label', fontsize = 16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, f1_score\n",
    "fpr, tpr, threshold = roc_curve(all_predictions['y'], all_predictions['turnout_ft_score'])\n",
    "roc_auc = roc_auc_score(all_predictions['y'], all_predictions['turnout_ft_score'])\n",
    "\n",
    "plt.title('Receiver Operating Characteristic Newest')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, f1_score\n",
    "fpr, tpr, threshold = roc_curve(all_predictions['y'], all_predictions['turnout_2016g'])\n",
    "roc_auc = roc_auc_score(all_predictions['y'], all_predictions['turnout_2016g'])\n",
    "\n",
    "plt.title('Receiver Operating Characteristic - 0ptimus Turnout Model')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "print('New Brier Score =', brier_score_loss(all_predictions['y'], all_predictions['turnout_ft_score']))\n",
    "print('Old Brier Score =', brier_score_loss(all_predictions['y'], all_predictions['turnout_2016g']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "from metricx import *\n",
    "df = pd.DataFrame.from_dict(expanded_calibration_curve(all_predictions['y'], all_predictions['turnout_ft_score']))\n",
    "df2 = pd.DataFrame.from_dict(expanded_calibration_curve(all_predictions['y'], all_predictions['turnout_2016g']))\n",
    "\n",
    "ggplot()\\\n",
    "+ geom_col(df2, aes(x=df2['target'], y=df2['percent_total']), fill='#ffc1b2', alpha=0.5)\\\n",
    "+ geom_col(df, aes(x=df['target'], y=df['percent_total']), fill='#e5e9ff', alpha=0.5)\\\n",
    "+ geom_line(df, aes(x=df['target'], y=df['percent_correct']), color = 'blue')\\\n",
    "+ geom_line(df2, aes(x=df2['target'], y=df2['percent_correct']), color = 'red')\\\n",
    "+ geom_abline(slope = 1, intercept = 0, color = 'grey') \\\n",
    "+ xlab('')  + ylab('Percent Correct')  \\\n",
    "+ xlim(0,1) + ylim(0,1) \\\n",
    "+ ggtitle('') \\\n",
    "+ theme_bw() \\\n",
    "+ theme(axis_text= element_text(size=10), axis_title = element_text(size=12), plot_title = element_text(size = 28))\n",
    "\n",
    "# ggplot.save(plot, 'calibration_histogram_compare_{}.png'.format(key), width = 8, height = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_hoc_calibration_score(all_predictions['y'], all_predictions['turnout_ft_score']),ad_hoc_calibration_score(all_predictions['y'], all_predictions['turnout_2016g'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE FEATURESET AND SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft_imputed_dummied.to_csv('featureset_mixed_train_turnout_2016g_id_l2.csv')\n",
    "test_ft_imputed_dummied.to_csv('featureset_mixed_score_turnout_2016g_id_l2.csv')\n",
    "all_predictions.to_csv('predictions_mixed_turnout_vh2016g_id_l2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "# plt.figure(figsize = (14,14))\n",
    "\n",
    "# j = 1\n",
    "\n",
    "# for i in thresholds:\n",
    "    \n",
    "#     yTestPred = all_predictions['turnout_ft_score'] > i\n",
    "    \n",
    "#     plt.subplot(3, 3, j)\n",
    "    \n",
    "#     j += 1\n",
    "    \n",
    "#     print('Threshold = ', i, ', recall = ', recall_score(all_predictions['y'], yTestPred),\n",
    "#           ', precision = ', precision_score(all_predictions['y'], yTestPred), \n",
    "#           ', f1_score = ', f1_score(all_predictions['y'], yTestPred))\n",
    "    \n",
    "#     sns.heatmap(confusion_matrix(all_predictions['y'], yTestPred).astype('float')/all_predictions.shape[0],\n",
    "#                 cmap=\"Blues\", annot=True, annot_kws={'size': 14},\n",
    "#                 vmin=0, vmax=1)\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.ylabel('Actual label')\n",
    "#     plt.title('Threshold = %0.1f' %i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "thresholds = np.linspace(0.0,1.0, 10)\n",
    "\n",
    "scoresRel = []\n",
    "for threshold in thresholds:\n",
    "    y_hat = (all_predictions['turnout_ft_score'].values < threshold).astype(int)\n",
    "    scoresRel.append([recall_score(y_pred = y_hat, y_true = all_predictions['y'].values), \\\n",
    "                  precision_score(y_pred = y_hat, y_true = all_predictions['y'].values), \\\n",
    "                  f1_score(y_pred = y_hat, y_true = all_predictions['y'].values)])\n",
    "    \n",
    "\n",
    "scoresRel = np.array(scoresRel)   \n",
    "plt.plot(thresholds, scoresRel[:, 0], label = 'Recall');\n",
    "plt.plot(thresholds, scoresRel[:, 1], label = 'Precision');\n",
    "plt.plot(thresholds, scoresRel[:, 2], label = 'F1 score');\n",
    "plt.legend(loc = 'upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "thresholds = np.linspace(0.0,1.0, 10)\n",
    "\n",
    "scoresRel = []\n",
    "for threshold in thresholds:\n",
    "    y_hat = (dfmerged['turnout_2016g'].values < threshold).astype(int)\n",
    "    scoresRel.append([recall_score(y_pred = y_hat, y_true = dfmerged['vh_2016g'].values), \\\n",
    "                  precision_score(y_pred = y_hat, y_true = dfmerged['vh_2016g'].values), \\\n",
    "                  f1_score(y_pred = y_hat, y_true = dfmerged['vh_2016g'].values)])\n",
    "    \n",
    "\n",
    "scoresRel = np.array(scoresRel)   \n",
    "plt.plot(thresholds, scoresRel[:, 0], label = 'Recall');\n",
    "plt.plot(thresholds, scoresRel[:, 1], label = 'Precision');\n",
    "plt.plot(thresholds, scoresRel[:, 2], label = 'F1 score');\n",
    "plt.legend(loc = 'upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerged[dfmerged['first_time_voter']==True].groupby(['vh_2016g','likely_voter_or'])['likely_voter_or'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerged.groupby(['vh_2016g','likely_voter_or'])['likely_voter_or'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train_mixed.corr()\n",
    "f, ax = plt.subplots(figsize = (14, 11))\n",
    "sns.heatmap(corrmat, vmax = 1, square = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
